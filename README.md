# 🌍 Personal Travel Assistant

A sophisticated AI-powered travel planning application that creates personalized travel itineraries based on user preferences. This project was developed as part of COMP8420 Assignment 2.



## 📋 Overview

The Personal Travel Assistant leverages large language models (LLMs) to generate customized travel plans. The system asks users about their travel preferences, processes this information, and creates a detailed itinerary tailored to their needs.

### 🌟 Key Features

- **Dual-model AI approach**: Compare travel plans generated by OpenAI's GPT and local Llama 3.2 models
- **Interactive dialogue system**: Conversational interface to collect travel preferences
- **User-friendly web interface**: Clean, intuitive Streamlit application with dark/light mode
- **Itinerary refinement**: Ability to adjust and improve generated travel plans
- **Export capabilities**: Save your travel plans in various formats

## 🔧 System Architecture

The application consists of three main components:

1. **LLM Setup**: Configuration for both cloud-based (OpenAI) and local (Llama 3.2) language models
2. **Dialogue System**: A structured conversation flow to collect user travel preferences
3. **Frontend Interface**: A responsive web application built with Streamlit

## 🚀 Installation

### Prerequisites

- Python 3.9+
- OpenAI API key
- Ollama (for local Llama model support)

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/personal-travel-assistant.git
   cd personal-travel-assistant
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Create an environment file**
   
   Create a `.env` file in the project root with your API keys:
   ```
   OPENAI_API_KEY=your_api_key_here
   ```

5. **Optional: Set up Ollama for local LLM**
   
   To use the local Llama model:
   - Install [Ollama](https://ollama.ai/)
   - Pull the Llama 3.2 model:
     ```
     ollama pull llama3.2
     ```

## 💻 Usage

### Web Interface

Run the application with the Streamlit interface:

```bash
python main.py
```

Or directly with:

```bash
streamlit run frontend.py
```

### Command Line Interface

Run the application in CLI mode:

```bash
python main.py --mode cli
```

### Testing LLMs

Test the LLM configurations:

```bash
python main.py --test-llm
```

## 📱 User Interface

The application features a clean, intuitive interface that guides users through the travel planning process:

1. **Welcome & Introduction**: Overview of the application features
2. **Preference Collection**: Series of questions about travel details and preferences
3. **Model Selection**: Choose between OpenAI or Llama models (or compare both)
4. **Itinerary Display**: View your generated travel plan
5. **Refinement**: Make adjustments to your plan as needed
6. **Export**: Save your travel itinerary for later use

## 🛠️ Project Structure

```
personal-travel-assistant/
├── main.py                # Entry point and command-line parsing
├── llm_setup.py           # LLM configuration and API handling
├── dialogue_system.py     # Dialogue flow and prompt construction
├── frontend.py            # Streamlit-based user interface
├── requirements.txt       # Dependencies
└── README.md              # Project documentation
```

## 🔄 LLM Comparison

The application allows users to compare travel plans generated by different models:

| Feature | OpenAI (GPT-3.5-Turbo) | Llama 3.2 |
|---------|------------------------|-----------|
| Style | More concise and focused | More detailed and comprehensive |
| Location Details | Better handling of specific locations | More creative activity suggestions |
| Response Time | Faster generation | Slower (running locally) |
| Price Estimation | Less detailed | Better price estimations |
| Privacy | Cloud-based service | Local deployment option |

## 🔮 Future Improvements

- Integration with external travel APIs for real-time pricing
- Map visualizations for itineraries
- User profiles for preference storage
- Mobile application development
- Additional language model options
- Fine-tuning models on travel-specific data

## 📝 License

This project is licensed under the MIT License - see the LICENSE file for details.

## 👥 Acknowledgments

- OpenAI for the GPT API
- Meta for the Llama model
- Streamlit for the frontend framework
- COMP8420 course for project guidance
