from llm_setup import query_openai_api, query_local_llama, compare_models

def create_dialogue_stages():
    """
    Create and return the dialogue stages for the travel assistant.
    
    Returns:
        list: List of dialogue stage dictionaries
    """
    dialogue_stages = [
        {
            "name": "introduction",
            "prompt": "Welcome to your personal travel assistant! I'll help you plan your perfect trip based on your preferences. I'll ask you a few questions to get started.",
            "required": False
        },
        {
            "name": "personal_info",
            "prompt": "Could you tell me a bit about yourself? (name, age, traveling alone or with others)",
            "required": True
        },
        {
            "name": "travel_destination",
            "prompt": "Where would you like to travel?",
            "required": True
        },
        {
            "name": "travel_dates",
            "prompt": "When are you planning to travel and for how long?",
            "required": True
        },
        {
            "name": "budget",
            "prompt": "What's your approximate budget for this trip (excluding flights)?",
            "required": True
        },
        {
            "name": "interests",
            "prompt": "What are your main interests for this trip? (e.g., historical sites, nature, food, adventure, relaxation)",
            "required": True
        },
        {
            "name": "accommodation_preference",
            "prompt": "What type of accommodation would you prefer? (e.g., luxury hotel, boutique hotel, hostel, apartment rental)",
            "required": False
        },
        {
            "name": "dietary_restrictions",
            "prompt": "Do you have any dietary restrictions or preferences I should consider?",
            "required": False
        },
        {
            "name": "additional_info",
            "prompt": "Is there anything else you'd like me to consider when planning your trip?",
            "required": False
        }
    ]
    
    return dialogue_stages

def construct_travel_prompt(user_responses):
    """
    Construct a detailed prompt for the LLM based on user responses.
    
    Args:
        user_responses (dict): Dictionary containing user responses
    
    Returns:
        str: Formatted prompt for the LLM
    """
    return f"""
    I need to create a personalized travel itinerary based on the following information:
    
    Personal Information: {user_responses.get('personal_info', 'Not provided')}
    Travel Destination: {user_responses.get('travel_destination', 'Not provided')}
    Travel Dates/Duration: {user_responses.get('travel_dates', 'Not provided')}
    Budget: {user_responses.get('budget', 'Not provided')}
    Interests: {user_responses.get('interests', 'Not provided')}
    Accommodation Preference: {user_responses.get('accommodation_preference', 'Not provided')}
    Dietary Restrictions: {user_responses.get('dietary_restrictions', 'Not provided')}
    Additional Information: {user_responses.get('additional_info', 'Not provided')}
    
    Based on this information, please create a detailed travel itinerary that includes:
    1. Day-by-day schedule with activities and attractions
    2. Recommended accommodations within their budget
    3. Suggested dining options that match their preferences and dietary needs
    4. Estimated costs for the major components of the trip
    5. Practical travel tips specific to their destination and preferences
    
    Format the itinerary in a clear, organized manner with headings and subheadings. 
    The itinerary should be well-structured, personalized to their interests, and respectful of their budget constraints.
    """

def generate_travel_plan(user_responses, model="openai"):
    """
    Generate a travel plan based on user responses using the specified model.
    
    Args:
        user_responses (dict): Dictionary containing user responses
        model (str): Model to use ("openai" or "llama")
    
    Returns:
        str: Generated travel plan
    """
    prompt = construct_travel_prompt(user_responses)
    
    if model == "openai":
        return query_openai_api(prompt)
    elif model == "llama":
        return query_local_llama(prompt)
    else:
        return "Error: Invalid model specified"

def compare_travel_plans(user_responses):
    """
    Compare travel plans generated by both models.
    
    Args:
        user_responses (dict): Dictionary containing user responses
    
    Returns:
        dict: Dictionary with travel plans from both models
    """
    prompt = construct_travel_prompt(user_responses)
    return compare_models(prompt)

def refine_travel_plan(original_plan, refinement_request, model="openai"):
    """
    Refine a travel plan based on user feedback.
    
    Args:
        original_plan (str): The original travel plan
        refinement_request (str): User's refinement request
        model (str): Model to use for refinement
    
    Returns:
        str: Refined travel plan
    """
    prompt = f"""
    Original travel plan:
    {original_plan}
    
    User requested refinements:
    {refinement_request}
    
    Please provide an improved travel plan addressing these specific requests while maintaining the original structure.
    Make the changes seamlessly so the plan still reads as a cohesive whole.
    """
    
    if model == "openai":
        return query_openai_api(prompt)
    elif model == "llama":
        return query_local_llama(prompt)
    else:
        return "Error: Invalid model specified"

def run_cli_dialogue():
    """
    Run the dialogue system in command-line interface mode.
    """
    print("=== Personal Travel Assistant ===")
    print("Let's plan your perfect trip!\n")
    
    dialogue_stages = create_dialogue_stages()
    user_responses = {}
    
    # Introduction
    print(dialogue_stages[0]["prompt"])
    
    # Collect responses for each stage
    for stage in dialogue_stages[1:]:  # Skip introduction
        print("\n" + stage["prompt"])
        user_input = input("> ")
        
        # Validate required fields
        while stage["required"] and not user_input.strip():
            print("This information is required to continue. Please provide a response.")
            user_input = input("> ")
        
        user_responses[stage["name"]] = user_input
    
    # Generate travel plans
    print("\nThank you for providing all the information! Generating your personalized travel plans...")
    
    plans = compare_travel_plans(user_responses)
    
    print("\n=== Your OpenAI Travel Plan ===\n")
    print(plans["OpenAI"])
    
    print("\n=== Your Llama 3.2 Travel Plan ===\n")
    print(plans["Llama 3.2"])
    
    # Get preference
    print("\nWhich travel plan do you prefer? (1 for OpenAI, 2 for Llama 3.2)")
    preference = input("> ")
    
    selected_plan = plans["OpenAI"] if preference == "1" else plans["Llama 3.2"]
    selected_model = "openai" if preference == "1" else "llama"
    
    # Offer refinement
    print("\nWould you like to refine the selected plan? (yes/no)")
    refine_choice = input("> ")
    
    if refine_choice.lower() in ["yes", "y"]:
        print("\nWhat aspects would you like to change or add to the plan?")
        refinement = input("> ")
        
        print("\nRefining your travel plan...")
        refined_plan = refine_travel_plan(selected_plan, refinement, selected_model)
        
        print("\n=== Your Refined Travel Plan ===\n")
        print(refined_plan)
    
    print("\nThank you for using the Personal Travel Assistant!")

# Run CLI dialogue if this file is executed directly
if __name__ == "__main__":
    run_cli_dialogue()